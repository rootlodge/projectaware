{
  "models": {
    "primary": {
      "name": "gemma3:latest",
      "description": "Small but hefty model for detailed analysis",
      "capabilities": ["text-to-text", "image-to-text", "multimodal"],
      "contextLimit": 32768,
      "temperature": {
        "default": 0.7,
        "analytical": 0.3,
        "creative": 0.9,
        "json": 0.1
      },
      "useCases": ["analysis", "reasoning", "creative", "multimodal"]
    },
    "fast": {
      "name": "llama3.2:latest",
      "description": "Fastest model with large context and tool support",
      "capabilities": ["text-to-text", "tool-usage", "function-calling"],
      "contextLimit": 131072,
      "temperature": {
        "default": 0.5,
        "analytical": 0.1,
        "creative": 0.7,
        "json": 0.0
      },
      "useCases": ["quick-responses", "tool-usage", "immediate", "conversation"]
    },
    "fallback": {
      "name": "llama3.1:latest",
      "description": "Reliable fallback model",
      "capabilities": ["text-to-text"],
      "contextLimit": 8192,
      "temperature": {
        "default": 0.6
      },
      "useCases": ["fallback", "basic"]
    }
  },
  "selection": {
    "strategy": "automatic",
    "rules": {
      "immediate_response": "fast",
      "analysis": "primary",
      "creative": "primary", 
      "multimodal": "primary",
      "tool_usage": "fast",
      "conversation": "fast",
      "refinement": "primary",
      "fallback": "fallback"
    },
    "performance_thresholds": {
      "response_time_ms": 5000,
      "max_retries": 3,
      "auto_fallback": true
    }
  },
  "ollama": {
    "base_url": "http://localhost:11434",
    "api_version": "v1",
    "timeout": 30000,
    "keep_alive": "5m"
  }
}
